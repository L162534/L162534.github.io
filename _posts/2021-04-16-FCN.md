---
layout:  post
title:  FCN,U-net
subtitle:  再入红尘
date:  2021-04-16
author:  LY
catalog:  true
tags:
	-语义分割
---

# FCN

## 优点：

* 将全连接层换成了卷积层，相当于将Dense层中单个神经元换成了卷积核，原文的结构中最后一个卷积层的w，h不一定是1x1，比如下图中最后一个全连接层是16x16x4096，然后通过21个4096x1x1的卷积操作将输出变成16x16x21的heatmap，这个过程相当于对16x16的特征图中每个像素作全连接层运算（**所谓的逐像素预测**），后面接着就是上采样层，为了让结果更加精细，将上采样的结果同上一层的卷积层特征进行特征融合，从而体现出更多的细节。
* 可以接受任意大小尺寸的图片，最后均能够输出同等大小的语义分割图。

![](\img\fcn-1.jpg)

橙色部分：通过反卷积实现的上采样层

灰色部分：剪裁层，用来统一层与层之间的大小

黄色部分：融合层
## 不足：

* 生成的分割图仍然不够精细


## 训练过程

并不是常规的端对端的训练，而是将训练分成四个部分：

* 第一部分：

  将全连接层去掉，载入预训练的权重

  ![](\img\fcn-3.jpg)

* 第二部分：

  直接将最后的16x16x21的heatmap上采样到原图大小进行训练

  ![](\img\fcn-2.jpg)

* 第三部分：

  将上采样分为两个阶段进行训练，这次融入了较低层的特征图

  ![](\img\fcn-4.jpg)

* 第四部分：

  将上采样分成三个阶段进行训练，进一步提高精确度

  ![](\img\fcn-5.jpg)

# U-Net

# 优点：

* 结构和FCN一样简单，参数量少，不易过拟合
* 支持少量训练数据训练

![](\img\fcn-1.png)

在特征融合的方法中与FCN不一样，FCN是直接将两个特征图越级相加，而U-Net是将两个特征图进行**拼接**，可能拼接能获得更好的原图细节



