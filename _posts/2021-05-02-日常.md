---
layout:  post
title:  日常
subtitle:  loss
date:  2021-05-02
author:  LY
catalog:  true
tags:
---

# 语义分割相关的loss

# 图像分割相关的loss

使用的最多的就是针对每个像素点做交叉熵CE，除此之外还有一些其他相关的loss：

## Dice loss

Dice coefficient(Dice 系数)是一种集合相似度度量函数，通常用于计算两个样本的相似度：


$$
s=\frac{2\left|X\bigcap Y\right|}{\left|X\right| + \left|Y\right|}
$$


是所以系数为2是因为重叠的部分需要重复计数

而用来衡量误差的Dice Loss表达式为：


$$
d = 1 - \frac{2\left|X \bigcap Y\right|}{\left|X\right| + \left|Y\right|}
$$


在图像分割中，
$$
\left|X\bigcap Y\right|
$$
就表示输出的各个像素的概率矩阵和groundtruth的点乘（二分类中只有gt图中只有0和1，所以不符合标签的会被0清零，在多分类中每个gt图的像素都是经过one-hot编码后的，所以同样可以采用点乘的形式用0将错误分类的结果清零），并将点乘后的结果进行相加；关于
$$
\left|X\right|和\left|Y\right|
$$
的量化计算，可直接采用简单的元素相加，或者取元素的平方并求和

* 优点：因为dice loss的优化目标同评价指标IoU几乎相同，更加易于理解，优化方向更加明确
* 缺点：Dice loss的梯度形式比较复杂，容易导致梯度非常大，使得训练过程不稳定

为了避免分母为0的情况，添加一个laplace smoothing：
$$
L_s = 1 - \frac{2\left|X \bigcap Y\right| + 1}{\left|X\right| + \left|Y\right| + 1}
$$


具体的pytorch代码实现如下：

```python
def make_one_hot(target, class_num):
    # 生成一个形状为(B,class,H,W) 形状的全零向量，这里的target形状为(B,1,H,W)
    
    one_hot = torch.FloatTensor(target.size()[0], class_num, target.size()[1], target.size()[2])._zeros().to(device=target.device)
    # 将对应索引位置的值变成1
    one_hot.scatter_(dim=1, index=target, 1)
    return one_hot

class DiceLoss(nn.Module):
    def __init__(self, smooth=1.):
        super(DiceLoss, self).__init__()
        self.smooth = 1.
    def forward(self, output, target):
        #给形状为(B,H,W)的target添加一个维度变成(B,1,H,W)
        target = make_one_hot(target.unsqueeze(dim=1), output.size()[1])
        output = nn.functional.softmax(output, dim=1)
        output_flat = output.contiguous().view(-1)
        target_flat = output.contiguousS().view(-1)
        intersection = (output_flat * target_flat).sum()
        # intersection = 2 * torch.mul(target, output).sum
        
        # enominator = torch.mul(output, output) + torch.mul(target, target)
        dice_loss = 1 - (2. * intersection + self.smooth)/(output_flat.sum() + target_flat.sum() + self.smooth)
        return dice_loss
```

## Focal Loss

Focal Loss是用来解决样本类别不均衡的问题，它是在CE Loss的基础上进行修改的，目的是通过减少易分类样本的权重，使得模型在训练时更加专注于难分类的样本;

回顾下二分类的交叉熵公式：


$$
\begin{aligned}
L&=-ylog\hat{y}-(1-y)log(1-\hat{y}) \\
&=\left\{\begin{matrix}
&-ylog\hat{y} & if \quad y=1 \\
&-(1-y)log(1-\hat{y}) & if \quad y=0
\end{matrix}\right.
\end{aligned}
$$
在目标检测中，大量的anchor都是负样本，只有少量的anchor是正样本，这就导致训练过程大多时候是由特别容易分类的负样本主导，并没有学到关键的信息，focal loss就是通过衰减易分类的样本所占loss的权重来让模型聚焦那些难分类的样本


$$
\begin{aligned}
L_{focal} = \left\{\begin{matrix}
&-y(1-\hat{y})^{\beta}log(\hat{y}) &if \quad y=1\\
&-(1-y)\hat{y}^{\beta}log(1-\hat{y}) &if \quad y=0
\end{matrix}\right.
\end{aligned}
$$
最后将加上平衡类样本数量的平衡因子
$$
\alpha
$$
,并将y值代入公式得到


$$
\begin{aligned}
L_{focal} = \left\{\begin{matrix}
&-\alpha(1-\hat{y})^{\beta}log(\hat{y}) &if \quad y=1\\
&-(1-\alpha)\hat{y}^{\beta}log(1-\hat{y}) &if \quad y=0
\end{matrix}\right.
\end{aligned}
$$
转换成统一的模式：


$$
L_{focal} = \frac{1}{N}\sum_{i=1}^{N}\alpha_{i}y_{i}(1-p_{i})^{\beta}log(p_{i})
$$
这里的
$$
\alpha_{i}
$$
可能会引起混淆，是yi对应那个类别所占的权重，假设一共有c个类别，则
$$
\alpha_{i}
$$
一共有c个值

```python
class FocalLoss(nn.Module):
    def __init__(self,alpha=0.25, beta=2):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.beta = beta
        # alpha是一个长度为class_num的tensor,这里就已经把alpha添加到loss的权重中去了
        self.CE_loss = nn.CrossEntropyLoss(reduction=None, weght=self.alpha)
    
    def foward(self, output, target):
        # log_pi是形状为(N,...)的tensor，和target形状相同,log_pi=-alog(pi),i=1~N
        
        log_pi = self.CE_loss(output, target)
        #个人觉得这里有问题，因为a已经添加到log_pi中去了，所以这里的pi=pi^a，不能看作是pi，如果看成是pi则后面的loss和FocalLoss的定义一致
        
        pi = torch.exp(-log_pi)
        loss = log_pi * ((1-pi) ** self.beta)
        return loss.sum
```

## Lovasz Loss

IoU的评判指标可以描述为：


$$
J_c(y^*,\hat{y})=\frac{|\{y^*=c\}\bigcap\{\hat{y}=c\}|}{|\{y^*=c\}\bigcup\{\hat{y}=c\}|}
$$
y*是groundtruth，
$$
\hat{y}
$$
是predict，c是相应的class，于是将loss定义为
$$
L=1-J_c(y^*,\hat{y})
$$
但是这个表达式是离散的，是不可导的，需要进行光滑延拓，采用lovasz extension数学工具进行光滑延拓，从而可以求导

```python
"""
Lovasz-Softmax and Jaccard hinge loss in PyTorch
Maxim Berman 2018 ESAT-PSI KU Leuven (MIT License)
https://github.com/bermanmaxim/LovaszSoftmax/blob/master/pytorch/lovasz_losses.py
"""

from __future__ import print_function, division

import torch
from torch.autograd import Variable
import torch.nn.functional as F
import numpy as np
try:
    from itertools import  ifilterfalse
except ImportError: # py3k
    from itertools import  filterfalse as ifilterfalse


def lovasz_grad(gt_sorted):
    """
    Computes gradient of the Lovasz extension w.r.t sorted errors
    See Alg. 1 in paper
    """
    p = len(gt_sorted)
    gts = gt_sorted.sum()
    intersection = gts - gt_sorted.float().cumsum(0)
    union = gts + (1 - gt_sorted).float().cumsum(0)
    jaccard = 1. - intersection / union
    if p > 1: # cover 1-pixel case
        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]
    return jaccard


def iou_binary(preds, labels, EMPTY=1., ignore=None, per_image=True):
    """
    IoU for foreground class
    binary: 1 foreground, 0 background
    """
    if not per_image:
        preds, labels = (preds,), (labels,)
    ious = []
    for pred, label in zip(preds, labels):
        intersection = ((label == 1) & (pred == 1)).sum()
        union = ((label == 1) | ((pred == 1) & (label != ignore))).sum()
        if not union:
            iou = EMPTY
        else:
            iou = float(intersection) / float(union)
        ious.append(iou)
    iou = mean(ious)    # mean accross images if per_image
    return 100 * iou


def iou(preds, labels, C, EMPTY=1., ignore=None, per_image=False):
    """
    Array of IoU for each (non ignored) class
    """
    if not per_image:
        preds, labels = (preds,), (labels,)
    ious = []
    for pred, label in zip(preds, labels):
        iou = []    
        for i in range(C):
            if i != ignore: # The ignored label is sometimes among predicted classes (ENet - CityScapes)
                intersection = ((label == i) & (pred == i)).sum()
                union = ((label == i) | ((pred == i) & (label != ignore))).sum()
                if not union:
                    iou.append(EMPTY)
                else:
                    iou.append(float(intersection) / float(union))
        ious.append(iou)
    ious = [mean(iou) for iou in zip(*ious)] # mean accross images if per_image
    return 100 * np.array(ious)


# --------------------------- BINARY LOSSES ---------------------------

def lovasz_hinge(logits, labels, per_image=True, ignore=None):
    """
    Binary Lovasz hinge loss
      logits: [B, H, W] Variable, logits at each pixel (between -\infty and +\infty)
      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)
      per_image: compute the loss per image instead of per batch
      ignore: void class id
    """
    if per_image:
        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))
                          for log, lab in zip(logits, labels))
    else:
        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))
    return loss


def lovasz_hinge_flat(logits, labels):
    """
    Binary Lovasz hinge loss
      logits: [P] Variable, logits at each prediction (between -\infty and +\infty)
      labels: [P] Tensor, binary ground truth labels (0 or 1)
      ignore: label to ignore
    """
    if len(labels) == 0:
        # only void pixels, the gradients should be 0
        return logits.sum() * 0.
    signs = 2. * labels.float() - 1.
    errors = (1. - logits * Variable(signs))
    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)
    perm = perm.data
    gt_sorted = labels[perm]
    grad = lovasz_grad(gt_sorted)
    loss = torch.dot(F.relu(errors_sorted), Variable(grad))
    return loss


def flatten_binary_scores(scores, labels, ignore=None):
    """
    Flattens predictions in the batch (binary case)
    Remove labels equal to 'ignore'
    """
    scores = scores.view(-1)
    labels = labels.view(-1)
    if ignore is None:
        return scores, labels
    valid = (labels != ignore)
    vscores = scores[valid]
    vlabels = labels[valid]
    return vscores, vlabels


class StableBCELoss(torch.nn.modules.Module):
    def __init__(self):
         super(StableBCELoss, self).__init__()
    def forward(self, input, target):
         neg_abs = - input.abs()
         loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()
         return loss.mean()


def binary_xloss(logits, labels, ignore=None):
    """
    Binary Cross entropy loss
      logits: [B, H, W] Variable, logits at each pixel (between -\infty and +\infty)
      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)
      ignore: void class id
    """
    logits, labels = flatten_binary_scores(logits, labels, ignore)
    loss = StableBCELoss()(logits, Variable(labels.float()))
    return loss


# --------------------------- MULTICLASS LOSSES ---------------------------


def lovasz_softmax(probas, labels, classes='present', per_image=False, ignore=None):
    """
    Multi-class Lovasz-Softmax loss
      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1).
              Interpreted as binary (sigmoid) output with outputs of size [B, H, W].
      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)
      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.
      per_image: compute the loss per image instead of per batch
      ignore: void class labels
    """
    if per_image:
        loss = mean(lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), classes=classes)
                          for prob, lab in zip(probas, labels))
    else:
        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), classes=classes)
    return loss


def lovasz_softmax_flat(probas, labels, classes='present'):
    """
    Multi-class Lovasz-Softmax loss
      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)
      labels: [P] Tensor, ground truth labels (between 0 and C - 1)
      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.
    """
    if probas.numel() == 0:
        # only void pixels, the gradients should be 0
        return probas * 0.
    C = probas.size(1)
    losses = []
    class_to_sum = list(range(C)) if classes in ['all', 'present'] else classes
    for c in class_to_sum:
        fg = (labels == c).float() # foreground for class c
        if (classes is 'present' and fg.sum() == 0):
            continue
        if C == 1:
            if len(classes) > 1:
                raise ValueError('Sigmoid output possible only with 1 class')
            class_pred = probas[:, 0]
        else:
            class_pred = probas[:, c]
        errors = (Variable(fg) - class_pred).abs()
        errors_sorted, perm = torch.sort(errors, 0, descending=True)
        perm = perm.data
        fg_sorted = fg[perm]
        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))
    return mean(losses)


def flatten_probas(probas, labels, ignore=None):
    """
    Flattens predictions in the batch
    """
    if probas.dim() == 3:
        # assumes output of a sigmoid layer
        B, H, W = probas.size()
        probas = probas.view(B, 1, H, W)
    B, C, H, W = probas.size()
    probas = probas.permute(0, 2, 3, 1).contiguous().view(-1, C)  # B * H * W, C = P, C
    labels = labels.view(-1)
    if ignore is None:
        return probas, labels
    valid = (labels != ignore)
    vprobas = probas[valid.nonzero().squeeze()]
    vlabels = labels[valid]
    return vprobas, vlabels

def xloss(logits, labels, ignore=None):
    """
    Cross entropy loss
    """
    return F.cross_entropy(logits, Variable(labels), ignore_index=255)


# --------------------------- HELPER FUNCTIONS ---------------------------
def isnan(x):
    return x != x
    
    
def mean(l, ignore_nan=False, empty=0):
    """
    nanmean compatible with generators.
    """
    l = iter(l)
    if ignore_nan:
        l = ifilterfalse(isnan, l)
    try:
        n = 1
        acc = next(l)
    except StopIteration:
        if empty == 'raise':
            raise ValueError('Empty mean')
        return empty
    for n, v in enumerate(l, 2):
        acc += v
    if n == 1:
        return acc
    return acc / n


class LovaszSoftmax(nn.Module):
    def __init__(self, classes='present',per_image=False):
        super(LovaszSoftmax, self).__init__()
        self.smooth = classes
        
    def forward(self, output, target):
        logits = torch.nn.functional.softmax(output, dim=1)
        loss = lovasz_softmax(logits, target)
        return loss
```

## CE_Dice Loss

就是将两种loss线性组合起来

```python
class CE_DiceLoss(nn.Module):
    def __init__(self, smooth=1, reduction='mean', ignore_index=255, weight=None):
        super(CE_DiceLoss, self).__init__()
        self.smooth = smooth
        self.dice = DiceLoss()
        self.cross_entropy = nn.CrossEntropyLoss(weight=weight, reduction=reduction, ignore_index=ignore_index)
    
    def forward(self, output, target):
        CE_loss = self.cross_entropy(output, target)
        dice_loss = self.dice(output, target)
        return CE_loss + dice_loss
```



# brain storming

* 让机器学会对图像的旋转变换，这样就可以通过训练少量样本就可以实现识别

* 样本不足的解决办法：

  1. 基于模型，通过简化模型，添加约束项来缩小假设空间
  2. 基于数据，数据增强

* scatter方法跟scatter_方法是一样的，只不过带\_的方法是in-place操作

  scatter(dim, index, src) dim是指定的轴，index是索引，src是输入的向量，该方法就是让src向量沿着dim轴按照index的索引取插入到目标向量中,其中source的形状必须和index形状一样或者能broadcast到和index形状一样

  > For a 3-D tensor, target is updated as:
  >
  > target[ index\[i]\[j]\[k] ]\[ j ]\[ k ] = src\[ i ]\[ j ]\[ k ] #if dim == 0
  >
  >  target[ i ]\[ index\[i]\[j]\[k] ]\[ k ] = src\[ i ]\[ j ]\[ k ] #if dim == 1
  >
  >  target[ i ]\[ j ]\[ index\[i]\[j]\[k] ] = src\[ i ]\[ j ]\[ k ] #if dim == 2

*  scatter相对应的逆操作时gather

  > Gather values along an axis specified by dim
  >
  > out\[ i ]\[ j ]\[ k ] = input[ index\[i]\[j]\[k] ]\[ j ][ k ] #if dim == 0

* is_contiguous()是用来判断tensor的存储顺序是否是和按行展开的一维数组顺序是一致的，C/C++中默认使用的按行优先，matlab，fortran使用的是列优先方式，pytorch的tensor底层使用C实现的，所以使用的是按行优先；

  contiguous()是用来保证tensor的存储顺序是按行优先方式顺序存储的，如果该tensor是连续存储的则不做任何改变，如果不是就会新开辟一个存储空间

  为什么需要contiguous呢？tensor的view操作是需要连续的tensor的，如果对一个他tensor做transpose、permute操作，虽然没有改变底层的数据，但是新建了一个元信息，其中改变了stride，这里的stride就是偏移量，矩阵就是通过偏移量来访问下一个元素，行优先stride是1，列优先的stride就是矩阵的行数。

  所以在进行view之前最好用contiguous保证tensor是连续的，其实tensor.contiguous.view()跟reshape()方法是一致的

* \left\\{\begin{matrix}

  &a &b &c \\

  &c &d &e

  \end{matrix}\right.
  $$
  \left\{\begin{matrix}
  &a &b &c \\
  &c &d &e
  \end{matrix}\right.
  $$

* 空格： \quad

  

