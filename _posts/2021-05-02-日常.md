---
layout:  post
title:  日常
subtitle:  loss
date:  2021-05-02
author:  LY
catalog:  true
tags:
---

# 语义分割相关的loss

# 图像分割相关的loss

使用的最多的就是针对每个像素点做交叉熵CE，除此之外还有一些其他相关的loss：

## Dice loss

Dice coefficient(Dice 系数)是一种集合相似度度量函数，通常用于计算两个样本的相似度：


$$
s=\frac{2\left|X\bigcap Y\right|}{\left|X\right| + \left|Y\right|}
$$


是所以系数为2是因为重叠的部分需要重复计数

而用来衡量误差的Dice Loss表达式为：


$$
d = 1 - \frac{2\left|X \bigcap Y\right|}{\left|X\right| + \left|Y\right|}
$$


在图像分割中，
$$
\left|X\bigcap Y\right|
$$
就表示输出的各个像素的概率矩阵和groundtruth的点乘（二分类中只有gt图中只有0和1，所以不符合标签的会被0清零，在多分类中每个gt图的像素都是经过one-hot编码后的，所以同样可以采用点乘的形式用0将错误分类的结果清零），并将点乘后的结果进行相加；关于
$$
\left|X\right|和\left|Y\right|
$$
的量化计算，可直接采用简单的元素相加，或者取元素的平方并求和

* 优点：因为dice loss的优化目标同评价指标IoU几乎相同，更加易于理解，优化方向更加明确
* 缺点：Dice loss的梯度形式比较复杂，容易导致梯度非常大，使得训练过程不稳定

为了避免分母为0的情况，添加一个laplace smoothing：
$$
L_s = 1 - \frac{2\left|X \bigcap Y\right| + 1}{\left|X\right| + \left|Y\right| + 1}
$$


具体的pytorch代码实现如下：

```python
def make_one_hot(target, class_num):
    # 生成一个形状为(B,class,H,W) 形状的全零向量，这里的target形状为(B,1,H,W)
    
    one_hot = torch.FloatTensor(target.size()[0], class_num, target.size()[1], target.size()[2])._zeros().to(device=target.device)
    # 将对应索引位置的值变成1
    one_hot.scatter_(dim=1, index=target, 1)
    return one_hot

class DiceLoss(nn.Module):
    def __init__(self, smooth=1.):
        self.smooth = 1.
    def forward(self, output, target):
        #给形状为(B,H,W)的target添加一个维度变成(B,1,H,W)
        target = make_one_hot(target.unsqueeze(dim=1), output.size()[1])
        output = nn.functional.softmax(output, dim=1)
        output_flat = output.contiguous().view(-1)
        target_flat = output.contiguousS().view(-1)
        intersection = (output_flat * target_flat).sum()
        # intersection = 2 * torch.mul(target, output).sum
        
        # enominator = torch.mul(output, output) + torch.mul(target, target)
        dice_loss = 1 - (2. * intersection + self.smooth)/(output_flat.sum() + target_flat.sum() + self.smooth)
        return dice_loss
```



# brain storming

* 让机器学会对图像的旋转变换，这样就可以通过训练少量样本就可以实现识别

* 样本不足的解决办法：

  1. 基于模型，通过简化模型，添加约束项来缩小假设空间
  2. 基于数据，数据增强

* scatter方法跟scatter_方法是一样的，只不过带\_的方法是in-place操作

  scatter(dim, index, src) dim是指定的轴，index是索引，src是输入的向量，该方法就是让src向量沿着dim轴按照index的索引取插入到目标向量中,其中source的形状必须和index形状一样或者能broadcast到和index形状一样

  > For a 3-D tensor, target is updated as:
  >
  > target[ index\[i]\[j]\[k] ]\[ j ]\[ k ] = src\[ i ]\[ j ]\[ k ] #if dim == 0
  >
  >  target[ i ]\[ index\[i]\[j]\[k] ]\[ k ] = src\[ i ]\[ j ]\[ k ] #if dim == 1
  >
  >  target[ i ]\[ j ]\[ index\[i]\[j]\[k] ] = src\[ i ]\[ j ]\[ k ] #if dim == 2

*  scatter相对应的逆操作时gather

  > Gather values along an axis specified by dim
  >
  > out\[ i ]\[ j ]\[ k ] = input[ index\[i]\[j]\[k] ]\[ j ][ k ] #if dim == 0

* is_contiguous()是用来判断tensor的存储顺序是否是和按行展开的一维数组顺序是一致的，C/C++中默认使用的按行优先，matlab，fortran使用的是列优先方式，pytorch的tensor底层使用C实现的，所以使用的是按行优先；

  contiguous()是用来保证tensor的存储顺序是按行优先方式顺序存储的，如果该tensor是连续存储的则不做任何改变，如果不是就会新开辟一个存储空间

  为什么需要contiguous呢？tensor的view操作是需要连续的tensor的，如果对一个他tensor做transpose、permute操作，虽然没有改变底层的数据，但是新建了一个元信息，其中改变了stride，这里的stride就是偏移量，矩阵就是通过偏移量来访问下一个元素，行优先stride是1，列优先的stride就是矩阵的行数。

  所以在进行view之前最好用contiguous保证tensor是连续的，其实tensor.contiguous.view()跟reshape()方法是一致的

