---
layout:  post
title:  学习tensorflow2(8)
subtitle:  retinanet
date:  2020-08-29
author:  L&X
catalog:  true
tags:
    -python
    -tensorflow
---

## 自定义层

在自定义层中的计算尽量不要用numpy库，要用tensorflow库中的方法去替代，因为在神经网络中的数据类型是tensor，用numpy的话数据类型是array，tensor变量有很多方法是array没有的，所以在训练的程中array类型的数据会报出很多错误。

自定义层一般要实现下列几种方法：

* __init_()_模型初始化方法
* build()初始化权重方法
* call()定义层内主要计算的方法
* compute_output_shape()计算输出形状的方法，一般用在输入和输出形状不一样的时候调用
* get_config()配置需要存储的参数方法，如果自定义层内的参数需要存储用于以后加载模型使用，要调用此方法

### anchor回归层

该层用于推理过程中将网络产生的anchor和regression通过计算得出最后的anchor

```python
class RegressBoxes(keras.layers.Layer):
    
    def __init__(self, mean=None, std=None, *args, **kwargs):

        if mean is None:
            mean = np.array([0, 0, 0, 0])
        if std is None:
            std = np.array([0.2, 0.2, 0.2, 0.2])
        self.mean = mean
        self.std  = std
        super(RegressBoxes, self).__init__(*args, **kwargs)

    def call(self, inputs, **kwargs):
        anchors, regression = inputs
        return backend.bbox_transform_inv(anchors, regression, mean=self.mean, std=self.std)

    def compute_output_shape(self, input_shape):
        return input_shape[0]

    def get_config(self):
        config = super(RegressBoxes, self).get_config()
        config.update({
            'mean': self.mean.tolist(),
            'std' : self.std.tolist(),
        })

        return config

```

本层没有需要训练的权重参数，所以不用实现build方法，但是需要存储mean和std的值，需要实现get_config()方法

本层代码的核心是call方法中的bbox_transform_inv()方法，该方法的输入是在原图中生成的初始anchor和每个 anchor对应的regression，具体实现目的就是将regression应用在每个anchor上，从而输出修正后的anchor。

具体实现代码：

```python
def bbox_transform_inv(boxes, deltas, mean=None, std=None):
    if mean is None:
        mean = [0, 0, 0, 0]
    if std is None:
        std = [0.2, 0.2, 0.2, 0.2]

    width  = boxes[:, :, 2] - boxes[:, :, 0]
    height = boxes[:, :, 3] - boxes[:, :, 1]

    x1 = boxes[:, :, 0] + (deltas[:, :, 0] * std[0] + mean[0]) * width
    y1 = boxes[:, :, 1] + (deltas[:, :, 1] * std[1] + mean[1]) * height
    x2 = boxes[:, :, 2] + (deltas[:, :, 2] * std[2] + mean[2]) * width
    y2 = boxes[:, :, 3] + (deltas[:, :, 3] * std[3] + mean[3]) * height

    pred_boxes = keras.backend.stack([x1, y1, x2, y2], axis=2)

    return pred_boxes

```

## 剪裁预测的box层

网络产生的box可能会超出原图像的边界 ，为了正常显示，我们需要对产生的box进行裁剪适应原图像大小。值得注意的是，由于这个自定义层没有任何需要记忆的参数值，所以甚至可以不需要init的初始化函数，最后需要实现的方法就只有call方法和compute_output_shape方法，具体的代码如下所示：

```python
class ClipBoxes(keras.layers.Layer):
    def call(self, inputs, **kwargs):
        image, boxes = inputs
        shape = tf.cast(tf.shape(image), tf.floatx())
        if keras.backend.image_data_format() == 'channels_first':
            _, _, height, width = backend.unstack(shape, axis=0)
        else:
            _, height, width, _ = backend.unstack(shape, axis=0)

        x1, y1, x2, y2 = tf.unstack(boxes, axis=-1)
        x1 = tf.clip_by_value(x1, 0, width  - 1)
        y1 = tf.clip_by_value(y1, 0, height - 1)
        x2 = tf.clip_by_value(x2, 0, width  - 1)
        y2 = tf.clip_by_value(y2, 0, height - 1)

        return tf.stack([x1, y1, x2, y2], axis=2)

    def compute_output_shape(self, input_shape):
        return input_shape[1]

```

## 筛选预测出的box层

```python
class FilterDetections(keras.layers.Layer):
    """ Keras layer for filtering detections using score threshold and NMS.
    """
    def __init__(
        self,
        nms                   = True,
        class_specific_filter = True,
        nms_threshold         = 0.5,
        score_threshold       = 0.05,
        max_detections        = 300,
        parallel_iterations   = 32,
        **kwargs
    ):
        self.nms                   = nms
        self.class_specific_filter = class_specific_filter
        self.nms_threshold         = nms_threshold
        self.score_threshold       = score_threshold
        self.max_detections        = max_detections
        self.parallel_iterations   = parallel_iterations
        super(FilterDetections, self).__init__(**kwargs)
        
        
    def call(self, inputs, **kwargs):
        """ Constructs the NMS graph.

        Args
            inputs : List of [boxes, classification, other[0], other[1], ...] tensors.
        """
        boxes          = inputs[0]
        classification = inputs[1]
        other          = inputs[2:]

        # wrap nms with our parameters
        def _filter_detections(args):
            boxes          = args[0]
            classification = args[1]
            other          = args[2]

            return filter_detections(
                boxes,
                classification,
                other,
                nms                   = self.nms,
                class_specific_filter = self.class_specific_filter,
                score_threshold       = self.score_threshold,
                max_detections        = self.max_detections,
                nms_threshold         = self.nms_threshold,
            )
         outputs = tf.map_fn(
            fn=_filter_detections,
            elems=[boxes, classification, others],
            # 输出数据的dtype
            dtype=[tf.float32, tf.float32, "int32"] + [o.dtype for o in others]
        )
        return outputs
    def compute_output_shape(self, input_shape):
        # 输入为(regression, classification, others), 输出为(regression, scores, labels, others)
        return [(input_shape[0][0], self.max_detections, 4),
                (input_shape[1][0], self.max_detections)
               ]

    def compute_mask(self, inputs, mask=None):
        return [len(inputs) + 1] * [None]

    def get_config(self):
        config = super(FilterDetections).get_config()
        config.update({
            "nms": self.nms,
            "class_specific_filter": self.class_specific_filter,
            "nms_threshold": self.nms_threshold,
            "score_threshold": self.score_threshold,
            "max_detections": self.max_detections,
        })
        return config    
        
```

**tf.map_fn**(fn， elems，dtype， paraparalle_iterations)函数将tensor列表或者队列沿着axis=0展开，再将每个列表中的elem代入fn映射函数中计算，最后将所有产生的结果再沿着axis=0堆叠形成原来的形状。本例中将每个batch的box进行筛选，最后在拼接成原来的形状。

因为该层的输入为[regression, classification, others], 输出是[regeression, scores, labels, others]， 输入和输出的形状不一样，因此需要重写compute_output_shape()

最关键的算法在_filter_detection函数，代码如下：

```python
def _filter_detections(scores, labels):

    indices = tf.where(tf.greater(scores, score_threshold))
    if nms:
        filtered_boxes = tf.gather_nd(boxes, indices)
        filtered_scores = tf.gather_nd(scores, indices)

        nms_indices = tf.image.non_max_suppression(filtered_boxes,
                                                   filtered_scores,
                                                   max_output_size=max_detections,
                                                   iou_threshold=nms_threshold)
        indices = tf.gather(indices, nms_indices)
   labels = tf.gather_nd(labels, indices)
   indices = tf.stack([indices[:, 0], labels], axis=1)
   return indices
```

该函数输入中的scores为预先入选的对应着某个class的某个anchor的匹配分数列表， 而labels就是就是这些匹配分数对应的class，他们的数量是一样的，具体的结构可大致描述成这样：

|       index       | scores |
| :---------------: | :----: |
| anchor1对应class1 |  0.1   |
| anchor1对应class2 |  0.2   |
| anchor2对应class1 |  0.3   |
| anchor2对应class2 |  0.4   |

labels的结构大致如下：

|       index       | labels |
| :---------------: | :----: |
| anchor1对应class1 |   1    |
| anchor1对应class2 |   2    |
| anchor2对应class1 |   1    |
| anchor2对应class2 |   2    |

再通过nms算法挑选出指定数量的detections，最后将这些detections的索引与labels合并

```python
def filter_detections(
        boxes,
        classification,
        others=None,
        class_specific_filter=True,
        nms=True,
        score_threshold=0.05,
        max_detections=200,
        nms_threshold=0.5
):


    if class_specific_filter:
        # 如果class_specific_filter为真，则会让每个anchor中对应的所有类别均参与_filter_detections的选择，否则只让每个anchor中score最大的类别参与选择
        all_indices = []
        for c in range(int(classification.shape[1])):
            scores = classification[:, c]
            labels = c * tf.ones(tf.shape(scores[0], ), dtype="int64")
            all_indices.append(_filter_detections(scores, labels))
        indices = keras.backend.concatenate(all_indices, axis=0)
    else:
        scores = tf.reduce_max(classification, axis=1)
        labels = tf.argmax(classification, axis=1)
        indices = _filter_detections(scores, labels)

    scores = tf.gather_nd(classification, indices)
    labels = indices[:, 1]
    scores, top_indices = tf.nn.top_k(scores, k=tf.minimum(max_detections, tf.shape(scores)[0]))
    indices = tf.gather(indices[:, 0], top_indices)
    boxes = tf.gather(boxes, indices)
    labels = tf.gather(labels, indices)
    other = [tf.gather(o, indices) for o in others]

    pad_size = tf.maximum(0, max_detections - tf.shape(scores)[0])
    boxes = tf.pad(boxes, [[0, pad_size], [0, 0]], constant_values=-1)
    scores = tf.pad(scores, [[0, pad_size], [0, 0]], constant_values=-1)
    labels = tf.pad(labels, [[0, pad_size], [0, 0]], constant_values=-1)
    labels = tf.cast(labels, "int32")
    other = [tf.pad(o, [[0, pad_size]] + [[0, 0] for _ in range(1, len(o.shape))], constant_values=-1) for o in other]
    boxes.set_shape([max_detections, 4])
    scores.set_shape([max_detections])
    labels.set_shape([max_detections])
    return [boxes, scores, labels, other]
```





## 算法实现的细节：

### 生成不同种类的anchor

```python
def generate_anchors(size, ratio, scale):
    """产生所有种类的anchor"""
    num_anchors = len(ratio) * len(scale)
    # 构造容纳所有种类尺寸的容器
    anchors = np.zeros((num_anchors, 4))
    # 先列出所有大小的anchor(边长相同), 分为两组
    anchors[:, 2:] = size * np.tile(scale, (2, len(ratio))).T
    # 求出所有尺寸的面积
    area = anchors[:, 2] * anchors[:, 3]
    # 将ratio应用到anchor尺寸中
    anchors[:, 2] = np.sqrt(area / np.repeat(ratio, len(scale)))
    anchors[:, 3] = anchors[:, 2] * np.repeat(ratio, len(scale))
    # 将anchors的格式从(0, 0, width, height)转换成(dx1, dy1, dx2, dy2)
    anchors[:, 0::2] = anchors[:, 0::2] - np.tile(anchors[:, 2]*0.5, (2, 1)).T
    anchors[:, 1::2] = anchors[:, 1::2] - np.tile(anchors[:, 3]*0.5, (2, 1)).T
    return anchors
```

结合提前设定的anchor大小、长宽比、扩张因子生成各种大小比例的anchor，下面假设size=10， ratios=[0.5, 1, 2], scales=[1, 1.5, 2]来描述算法的具体实现：由ratios和scales可知共有9种不同的anchor

![](D:\Documents\GitHub\L162534.github.io\img\retinanet-1.jpg)

首先创建装载anchor坐标的二维数组，shape=(9, 4), 注意图中是先将size乘以scales，后面再乘以ratios， 代码中是先乘以ratios，再乘以scales，最后实现的效果还是一样的。用size乘以scales后就得到了三种不同尺寸的长和宽（长和宽相同），再求出三种不同尺寸的面积，再根据不同的ratio比例和面积求出九种长和宽的组合，图中第二行是为了将anchor的长和宽转换成四个坐标点，用第一列和第三列减去width的一半，用第二列和第四列减去height的一半，即可求出四个坐标，其实这四个坐标其实可以理解为偏移量，是相对于anchor中心的偏移量。

### 将生成的所有anchor及label经过筛选转换成最终的训练数据

```python
def compute_anchor_targets(
        anchors,
        image_group,
        annotations_group,
        num_classes,
        negative_overlap=0.4,
        positive_overlap=0.5
):
    assert(len(image_group)==len(annotations_group)), "The length of image_gourp and annotations_group must be equal"

    batch_size = len(image_group)
    # 最后一维有5个参数，包括x1, y1, x2, y2和flag(正负样本的标志)
    regression_batch = np.zeros((batch_size, anchors.shape[0], 4+1), dtype=np.float32)
    label_batch = np.zeros((batch_size, anchors.shape[0], num_classes+1), dtype=np.float32)
    for index, (image, annotations) in enumerate(zip(image_group, annotations_group)):
        if annotations["bboxes"].shape[0]:
            positive_indices, ignore_indices, argmax_overlaps_inds = compute_gt_annotations(anchors, annotations["bboxes"], negative_overlap, positive_overlap)
            label_batch[index, ignore_indices, -1] = -1
            label_batch[index, positive_indices, -1] = 1
            regression_batch[index, ignore_indices, -1] = -1
            regression_batch[index, positive_indices, -1] = 1
            # argmax_overlaps_inds是每个anchor对应的最大重叠的annotation的列表，通过positive_indices找到正样本的annotation的索引,
            # 再通过 annotations["labels"]找到该annotation的class，最后对label_batch中的这个class置1
            label_batch[index, positive_indices, annotations["labels"][argmax_overlaps_inds[positive_indices]].astype(int)] = 1
            regression_batch[index, :, :-1] = bbox_transform(anchors, annotations["bboxes"][argmax_overlaps_inds, :])
        # 在各个特征层产生的anchor有可能超出原图像
        if image.shape:
            anchors_centers = np.vstack(((anchors[:, 0]+anchors[:, 2])/2, (anchors[:, 1]+anchors[:, 3])/2)).T
            indices = np.logical_or(anchors_centers[:, 0] >= image.shape[1], anchors_centers[:, 1] >= image.shape[0])
            label_batch[index, indices, -1] = -1
            regression_batch[index,  indices, -1] = -1

    return regression_batch, label_batch
```

该函数产生最终输出，数据形状为((batch_size， anchor_num， 5），（batch_size， anchor_num， num_class+1))

前面的部分是regression， 后面的为classification，这两组的每份数据数据最后都加了一位用来表示该份数据的属性positive(1)，negative(0)，ignore(-1)

bbox_transform函数是根据annotation的坐标和anchor的坐标求出annotation与anchor每个坐标点的偏移量

### 筛选我们生成的所有anchor中符合正样本的的anchor

```python
def compute_gt_annotations(anchors, annotations, negative_overlap=0.4, positive_overlap=0.5):
    overlaps = compute_overlap(anchors.astype(np.float64), annotations.astype(np.float64))
    argmax_overlaps_inds = np.argmax(overlaps, axis=1)
    max_overlaps = overlaps[np.arange(overlaps.shape[0]), argmax_overlaps_inds]
    positive_indices = max_overlaps >= positive_overlap
    ignore_indices = (max_overlaps > negative_overlap) & ~positive_indices
    # 返回anchor正样本的索引，中性样本的索引，每个anchor重合面积最大的annotation的索引
    return positive_indices, ignore_indices, argmax_overlaps_inds
```

这里的overlaps的数据结构是每个anchor和每个annotation的IOU，是一个二维数组，如下表结构所示：

|         | annotation1 | annotation2 | annotation3 | annotation4 | annotation5 |
| ------- | ----------- | ----------- | ----------- | ----------- | ----------- |
| anchor1 | 0.1         | 0.9         | 0.6         | 0.4         | 0           |
| anchor2 | 0.9         | 0.5         | 0.4         | 0.6         | 0.1         |
| anchor3 | 0           | 0.4         | 0.6         | 0.9         | 0.2         |

argmax_overlaps_inds就是求每个anchor中与哪个annotation的IOU最大的索引，以上表为例，就是[1, 0, 3] (默认以0开头)

max_overlaps就是根据上面的索引求每个每个anchor的最大重叠面积， 并根据设定的阈值将这些anchor分为正样本和中性可忽略的样本， 如上表为例就是[0.9, 0.9, 0.9] 





## 数据结构

* 神经网络的输入：

## 需要思考的问题

* 在最后的分类子模型中，最后一层的卷积层的bias_initializer为什么要用先验概率？

* 在自定义层filter_detection中为什么要重写compute_mask函数？

* 为什么会出现val_loss上升而val_accuracy同样上升的现象？

  可能由部分极端数据造成，假如标签为[1, 0, 0], pre1=[0.2, 0.1,  0.1], pre2=[0.501, 0.499, 0.499], 假设阈值取0.5，很明显pre2的正确率比pre1高，但是pre2的loss要比pre1高
  
* 在focal loss的设计过程中，其采用了归一化的形式，但是归一化最后是将正负样本的交叉熵求和除以正样本的数量，为什么？

  在实际操作过程中，如果除以正负样本的数量，最后的loss值会非常非常小，不利于误差传递；从我个人在理论上来理解，因为正样本的的权重没有受到衰减，所以传递的loss除以正常范围，但是负样本受到了较大的衰减，单个负样本对loss的贡献极小，打个比方，一个正样本带来的loss是3，一个负样本带来的loss是0.1，假设有10个正样本，100个负样本，那么总的loss是40， 如果除以10个正样本的数量，则平均每个样本带来的loss是4，仍处于正常范围，如果除以110， 则平均每个样本带来的loss是0.36，会使误差传递的速度大大降低。

