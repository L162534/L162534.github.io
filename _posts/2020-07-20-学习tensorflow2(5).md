---
layout:  post
title:  学习tensorflow2(5)
subtitle:  抓紧学！来不及了
date:  2020-07-20
author:  L&X
catalog:  true
tags:
    -深度学习框架
---

## padding问题

在tf2中调用tf.keras.layers.Conv2D()当padding=‘same’时，无论卷积核大小是多少，最后图像大小取决于原图像大小和strides的大小。

## tensorflow2训练模型方法

1. 采用内置集成的训练函数tf.keras.fit()

   支持对numpy.array、tf.data.Dataset、generator多种数据类型进行训练

   首先将一个已经构建好的网络模型进行编译配置：

   ```python
   model.compile(optimizer=tf.keras.optimizers.Adam(0.001),
                loss=tf.keras.losses.categorical_crossentropy,
                metrics=[tf.keras.metrics.categorical_accuracy])
   ```

   然后直接调用fit方法

   ```
   history = model.fit(ds_train, validation_data = ds_val,epooch)
   ```

2. 采用内置的train_on_batch方法，自己编写基于batch的层次上进行训练的函数

   同样先对模型进行编译配置，代码同上，然后编写针对每个批次的训练函数：

   ```python
   def train_model(model, ds_train, ds_val, epoch):
       for epch in tf.range(1, epoch+1)
   	model.reset_metrics()
       for x, y in ds_train:
           train_result = model.train_on_batch(x, y)
       for x, y in ds_val:
           val_result = model.test_on_batch(x, y, reset_metrics=False)
       if epoch%1 == 0:
           printbar()
           tf.print("epoch = ",epoch)
           print("train:",dict(zip(model.metrics_names,train_result)))
           print("valid:",dict(zip(model.metrics_names,valid_result)))
   
   ```

3.  自定义训练循环

   连compile函数都不用，自己直接调用优化器迭代更新参数，灵活性最高

   ```python
   optimizer = tf.keras.optimizers,adam()
   loss_func = tf.keras.losses.SparseCategoricalCrossentropy()
   train_loss = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')
   train_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')
   
   def train_step(model, features, labels):
       with tf.GradientTape() as tape:
           predictions = model(features, training = True)
           loss = loss_func(labels, predictions)
       gradients = tape.gradient(loss, model.trainable_variables)
       optimizer.apply_gradients(zip(gradients, model.trainable_variables))
       train_loss.update_state(loss)
       train_metirc.update_state(labels, predictions)
       
   def validate_step(model, features, labels):
       predictions = model(features)
       batch_loss = loss_func(labels, predictions)
       val_loss.update_state(batch.loss)
       bal_metric.update_state(labels, predictions)
       
       
   def train_model(model, ds_train, ds_val, epochs):
       for epoch in tf.range(1, epochs+1):
           for features, labels in ds_train:
               train_step(model, features, labels)
           for features, labels in ds_val:
               validate_step(model, features, labels)
   		logs = 'Epoch={},Loss:{},Accuracy:{},Valid Loss:{},Valid Accuracy:{}'
           
           if epoch%1 ==0:
               printbar()
               tf.print(tf.strings.format(logs,
               (epoch,train_loss.result(),train_metric.result(),valid_loss.result(),valid_metric.result())))
               tf.print("")
               
           train_loss.reset_states()
           valid_loss.reset_states()
           train_metric.reset_states()
           valid_metric.reset_states()
   ```

   