---
layout:  post
title:  PSPNet
subtitle:  keep moving
date:  2021-06-02
author:  LY
catalog:  true
tags:
    -语义分割
---

# 增大感受野的手段

1. 增大卷积的stride，例如空洞卷积（DeepLab)，池化操作，例如全局均值池化（PSPNet）
2. 浅层特征和深层特征相互融合(FCN)

# PSPNet执行流程

![](D:\Documents\GitHub\L162534.github.io\img\PSPNet.png)

主干网络采用离散卷积的ResNet，再将整个特征层送入到池化模块

1. 池化模块的输出大小包括1x1,2x2,3x3,6x6,先将特征层通过池化
2. 再通过卷积层压缩特征通道，通道数为初始特征层数/池化核种类数
3. 将压缩通道的池化输出上采样到特征层的尺寸
4. 将上采样结果与原来的特征层进行拼接
5. 最后通过全卷积输出

# 代码实现

## PSP模块

输入：输入特征维数，池化核尺寸列表，归一化层种类

```python
class _PSPModule(nn.Module):
    def __init__(self, in_channels, bin_sizes, norm_layer):
        super(_PSPModule, self).__init__()
        # 将特征尺寸按照池化核种类个数平均分配
        
        out_channels = in_channels // len(bin_sizes)
       	# 通过池化核池化和通道压缩后的输出
        
        self.stages = nn.ModuleList([self._make_stages(in_channels, out_channels, b_s, norm_layer) 
                                                        for b_s in bin_sizes])
        # 将池化结果拼接特征层后的卷积操作
        
        self.bottleneck = nn.Sequential(
            nn.Conv2d(in_channels+(out_channels * len(bin_sizes)), out_channels, 
                                    kernel_size=3, padding=1, bias=False),
            norm_layer(out_channels),
            nn.ReLU(inplace=True),
            nn.Dropout2d(0.1)
        )
        
    def _make_stages(self, in_channels, out_channels, bin_sz, norm_layer):
        prior = nn.AdaptiveAvgPool2d(output_size=bin_sz)
        conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)
        bn = norm_layer(out_channels)
        relu = nn.ReLU(inplace=True)
        return nn.Sequential(prior, conv, bn, relu)
    
    def forward(self, features):
        h, w = features.size()[2], features.size()[3]
        pyramids = [features]
        # 上采样后将结果存到pyramids
        
        pyramids.extend([F.interpolate(stage(features), size=(h, w), mode='bilinear', 
                                       align_corners=True) for stage in self.stages])
        output = self.bottleneck(torch.cat(pyramids, dim=1))
        return output
```

# brainstorming

* nn.ModuleList 和 nn.Sequential

  ModuleList定义了一系列的网络层，并将网络层注册到网络中，但是没有定义ModuleList中网络层的连接情况，如果用list存，网络层中的参数并不会注册到网络中；而Sequential更适用于那些模块的搭建，直接注册好网络层以及网络层的连接情况
  
* numpy的数组形式切片

  a = np.arange(25).reshape((5,5))

  取出第二到三行，四到五列的数据：b = a[1:3, 3:5]

  增加一个维度： c = a[:,:, None] None在哪个位置就在哪个地方增加维度

  在某个维度上按照step步进选取元素[::step]

  [...]可以用来替代所有冒号: a[1,:,:] = a[1,...]

  实际应用：对一个图像矩阵进行水平翻转，img1 = img[:,::-1,...]