---
layout:  post
title:  日常
subtitle:  再出红尘
date:  2021-04-19
author:  LY
catalog:  true
tags:
    -深度学习框架
    -语义分割
---

# 基于pytorch用U-net实现图像语义分割

## 数据准备阶段

**Dataset类**

Dataset是pytorch数据集的基类,他是一个map形式构建出的数据集,key是indice,value是data,所有子类都必须重写\_\_gettiem\_\_()方法(根据索引取出数据),也可以选择性重写\_\_len\_\_()方法,用来返回数据集的尺寸.

```python

class Dataset(object):
    r"""An abstract class representing a :class:`Dataset`.

    All datasets that represent a map from keys to data samples should subclass
    it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a
    data sample for a given key. Subclasses could also optionally overwrite
    :meth:`__len__`, which is expected to return the size of the dataset by many
    :class:`~torch.utils.data.Sampler` implementations and the default options
    of :class:`~torch.utils.data.DataLoader`.

    .. note::
      :class:`~torch.utils.data.DataLoader` by default constructs a index
      sampler that yields integral indices.  To make it work with a map-style
      dataset with non-integral indices/keys, a custom sampler must be provided.
    """

    def __getitem__(self, index):
        raise NotImplementedError

    def __add__(self, other):
        return ConcatDataset([self, other])
```

**自定义一个Dataset**

首先要明确自己想实现的功能:

1. 初始化方法\_\_init\_\_()

   一般包含图片目录,图片尺寸,由于本例是语义分割所以还要包含mask目录

2. \_\_len\_\_()

3. \_\_getitem\_\_()

4. 图片预处理方法preprocess()

``` python
class BasicDataset(Dataset):
    def __init__(self, imgs_dir, masks_dir, size, mask_suffix='',data_mode='jpg'): # 为了方便原图和mask图的管理,直接在原图名后加mask后缀作为mask图的名字
        self.imgs_dir = imgs_dir
        self.masks_dir = masks_dir
        self.size = size
        self.mask_suffix = mask_suffix
        self.data_mode = data_mode
        self.ids = [os.path.splitext(file)[0] for file in os.listdir(imgs_dir) if not file.startswith('.')]# 为所有图片建立索引
    	logging.info(f'dataset has {len(self.ids)} images')
        
    def __len__(self):
        return len(self.ids)
    ## 重写父类的方法
    def __getitem__(self,index):
        idx = self.ids[index]
        img_file = glob.glob(self.imgs_dir + idx + '.*') #这种方法相较精确输入文件名更鲁棒更简洁
        mask_file = glob.glob(self.masks_dir + idx + '.*')
        img = decode_file(img_file[0], self.data_mode)
        mask = decode_file(mask_file[0], self.data_mode)
        img = preprocess(img, self.size)
        mask = preprocess(mask, self.size)
        
    def decode_file(file_dir, data_mode='jpg'):
        if data_mode == 'jpg':
            return np.asarray(PIL.Image.open(file_dir))
       	if data_mode == 'mat':
            return asarray(scipy.io.loadmat(file_dir)['groundtruth']) #这里根据具体的数据格式进行相应的调整
    	else:
            raise ValueError("can't decode the type of {}".format(data_mode))
    @classmethod # 用该修饰符修饰后,该函数可以直接被类调用而不用具体的实例,被该修饰符修饰后第一个参数应该是cls,该参数指代该类本身
    def preprocess(cls, img_array, size):  # 用这个修饰符是为了让这个方法在没有实例也可以调用,就像调用包中的方法一样
        # opencv的size参数是(w,h)不是默认的(h,w),所以要进行转化
        img = resize(img_array, dsize=(size[1], size[0]))
        # 给mask添加c通道，为了跟图片统一执行后面的函数，直接将channel通道加在最后面
        if len(img_array.shape) == 2:
            img = np.expand_dims(img, axis=2)
            # HWC -> CHW
            img = img.transpose((2, 0, 1))
            if img.max() > 1:
                img = img / 255
                return img

#测试代码
if __name__ == '__main__':
    dataset = BasicDataset(imgs_dir=r'D:\Documents\PycharmProject\dataset\photos/',
                           masks_dir=r'D:\Documents\PycharmProject\dataset\annotations\pixel-level/',
                           size=(830, 550))
    img = (dataset.__getitem__(1))['image']
    img = np.asarray(img)
    img = img.transpose((1,2,0))
    plt.imshow(img)
    plt.show()
```

## 训练设置阶段

1. 切分成训练集和验证集，并设置相应的batch_size,打乱顺序，同时启用tesorboard将需要保存的张量值写入tensorboard

   ```python
   imgs_dir = r' ***/'
   masks_dir = r'***/'
   checkpoint_dir = r'**/checkpoint'
   img_size = (400, 250)
   
   dataset = BasicDataset(imgs_dir=imgs_dir,
                              masks_dir=masks_dir,
                              size=img_size,
                              mask_suffix='mask',
                              data_mode='jpg',
                              mask_mode='mat')
       n_val = int(len(dataset) * val_percent)
       n_train = len(dataset) - n_val
       train, val = random_split(dataset, [n_train, n_val])
       # num_workers用来设置线程数，默认是0，取其他值会报页面文件太小，无法完成操作的错误
       # pin_memory是设置锁页内存，设置为True时锁页内存的Tensor不会转到虚拟内存中，从而在转到gpu时会更快，主机内存转设备内存正常的流程是：主机可分页内存->主机的固定内存->设备端的内存
       train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)
       val_loader = DataLoader(val, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)
       writer = SummaryWriter(log_dir='data/tensorboard', comment=f'LR{lr}-BS{batch_size}-SCALE{img_size}')
       global_step = 0
       logging.info(f'''
           Epochs: {epochs}
           Batch size: {batch_size}
           Learning rate: {lr}
           Training size: {n_train}
           Validation size: {n_val}
           Checkpoints: {save_model}
           Device: {device.type}
           Image size: {img_size}
   ''')
   ```

2. 设置相应的优化器，学习率策略器和损失函数

   ```python
   optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)
   # 通过每次迭代训练的结果去改变学习率
   # min是求最小值，patience=2表示如果经过2个epoch，所监听的变量没有变小则降低学习率
   scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2)
   criterion = nn.CrossEntropyLoss()
   ```

3. 编写相应的验证函数

   ```python
   def eval_net(net, loader, device):
       # 设置模型为判别模式
       net.eval()
       # 将mask的标签转换成长整型，方便后面计算交叉熵时转换成one-hot向量
       mask_type = torch.long
       n_val = len(loader)
       total_loss = 0
       with tqdm(total=n_val, desc='Validation') as pbar:
           for batch in loader:
               img_batch = batch['image']
               mask_batch = batch['mask']
               # 将image和mask的样本转到gpu上
               img_batch = img_batch.to(device=device, dtype=torch.float32)
               mask_batch = mask_batch.to(device=device, dtype=mask_type)
               # 这里的mask_batch的形状是(N,1,H,W),所以需要将第二个维度去掉
               mask_batch = torch.squeeze(mask_batch, axis=1)
               with torch.no_grad():
                   mask_pred = net(img_batch)
               # 将标量tensor转换成python数值
               total_loss += cross_entropy(mask_pred, mask_batch).item()
               pbar.update()
       net.train()
       return total_loss/n_val
   ```

4. 编写训练阶段函数 

   ```python
   def train_net(net, device, epochs=5, batch_size=1, lr=0.001, val_percent=0.1,
                 save_model=True, img_size=img_size, resume=False, checkpoint_dir=None):
       dataset = BasicDataset(imgs_dir=imgs_dir,
                              masks_dir=masks_dir,
                              size=img_size,
                              mask_suffix='mask',
                              data_mode='jpg',
                              mask_mode='mat')
       n_val = int(len(dataset) * val_percent)
       n_train = len(dataset) - n_val
       train, val = random_split(dataset, [n_train, n_val])
       train_loader = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)
       val_loader = DataLoader(val, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)
   
       writer = SummaryWriter(log_dir='data/tensorboard')
       global_step = 0
       logging.info(f'''
           Epochs: {epochs}
           Batch size: {batch_size}
           Learning rate: {lr}
           Training size: {n_train}
           Validation size: {n_val}
           Checkpoints: {save_model}
           Device: {device.type}
           Image size: {img_size}
   ''')
       optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)
       # 通过每次迭代训练的结果去改变学习率
       scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2)
       criterion = nn.CrossEntropyLoss()
       min_val_loss = 100
       start_epoch = 0
       # 增加的断点续练的功能
       if resume:
           latest_file = os.listdir(checkpoint_dir)[-1]
           if os.path.isfile(latest_file):
               checkpoint = torch.load(latest_file)
               start_epoch = checkpoint['epoch'] + 1
               net.load_state_dict(checkpoint['model'])
               optimizer.load_state_dict(checkpoint['optimizer'])
               print('loading model and optimizer')
            else:
               print(f'can not find any checkpoint under {checkpoint_dir}')
           for epoch in range(start_epoch, epochs):
               net.train()
               epoch_loss = 0
               with tqdm(total=n_train, desc=f'Epoch {epoch+1}/{epochs}', unit='img') as pbar:
                   for batch in train_loader:
                       img_batch = batch['image']
                       img_batch =  img_batch.to(device=device, dtype=torch.float32)
                       mask_batch = batch['mask']
                       mask_batch = mask_batch.to(device=device, dtype=torch.long)
                       mask_batch = torch.squeeze(mask_batch, dim=1)
                       mask_pred = net(img_batch)
                       loss = criterion(mask_pred, mask_batch)
                       print(f'loss:{loss}')
                       epoch_loss += loss
                       writer.add_scalar('loss', loss.item(), global_step=global_step)
                       global_step += 1
                       optimizer.zero_grad()
                       loss.backward()
                       nn.utils.clip_grad_value_(net.parameters(), 0.1)
                       optimizer.step()
                       pbar.update(img_batch.shape[0])
                   # for tag, value in net.named_parameters():
                   #     tag = tag.replace('.', '/')
                   #     writer.add_histogram('weights/' + tag, value.data.cpu().numpy(), global_step)
               val_loss = eval_net(net, val_loader, device)
               if val_loss < min_val_loss:
                   min_val_loss = val_loss
               scheduler.step(val_loss)
               writer.add_scalar('lr', optimizer.param_groups[0]['lr'], global_step)
               logging.info('validatoin crossentropy:{}'.format(val_loss))
               writer.add_scalar('val_loss', val_loss, global_step)
               writer.add_images('images', img_batch, global_step)
               print(f'train average loss:{epoch_loss/n_train*batch_size}')
               if save_model:
                   if os.path.exists(checkpoint_dir):
                       if val_loss != min_val_loss:
                           checkpoint = {
                               'epoch': epoch,
                               'model': net.state_dict(),
                               'optimizer': optimizer.state_dict()
                           }
                           torch.save(checkpoint, checkpoint_dir + rf'\epoch{epoch + 1}.pth')
                           print(f'saving epoch{epoch + 1}.pth')
                           logging.info(f'Checkpoint {epoch + 1} saved')
                       else:
                           print('the loss did not decrease, do not save this epoch model')
                   else:
                       print("can't find the path {}".format(checkpoint_dir))
           writer.close()
   ```

# 预测阶段

1. 编写单张预测函数： 

   ```python
   def predict_img(net, full_img, device, size, n_classes=59):
       net.eval()
       # 调用之前用classmethod修饰的方法，注意方法里的image是array格式
       img = torch.from_numpy(BasicDataset.preprocess(np.asarray(full_img), size=size))
       # 给图片array加上batch维度
       img = torch.unsqueeze(img, axis=0)
       img = img.to(device=device, dtype=torch.float32)
       with torch.no_grad():
           output = net(img)
           # 去除batch维度，此时的输出形状是(classes, H, W)
           output = output.squeeze(0)
           # 将输出归一化
           probs = torch.nn.functional.softmax(output, dim=0)
           probs = probs.cpu().numpy()
           # 求出在classes维度中概率最大的class的索引
           indices_img = probs.argmax(axis=0)
           # 再将索引除以总的类别数进行归一化，转换成相应的0~1之间的像素值
           indices_img_norm = indices_img / n_classes
       return indices_img_norm
   ```
   
2. 编写预测函数

   ```python
   img_file = "0036.jpg"
   out_file = get_output_filenames(img_file)
   size = (400, 250)
   model_path = "checkpoint/epoch24.pth"
   net = UNet(n_channels=3, n_classes=59)
   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
   net.to(device=device)
   checkpoint = torch.load(model_path, map_location=device)
   net.load_state_dict(checkpoint['model'])
   img = Image.open(img_file)
   mask = predict_img(net=net,
   full_img=img,
   device=device,
   size=size,
   )
   plt.figure()
plt.subplot(1, 2, 1)
   plt.imshow(Image.open(img_file))
   plt.subplot(1, 2, 2)
   plt.imshow(mask)
   plt.show()
   ```
   
   

# 交叉熵

## 熵：H(X)

意义：事件X发生蕴含的信息量，事件发生的概率越小其蕴含的信息量越大

假设对于事件X，有n种可能性，发生的概率为p(xi),则事件X包含的信息量H(X):
$$
H(X) = -\sum_{i=1}^{n}p(x_{i})log(x_{i})
$$

假设事件X是我买彩票中的奖：

| 序号 | 事件       | 概率  | 信息量（I） |
| ---- | :--------- | ----- | ----------- |
| A    | 中了头等奖 | 0.001 | -log(p(A))  |
| B    | 中了1块    | 0.099 | -log(p(B))  |
| C    | 谢谢惠顾   | 0.9   | -log(p(C))  |

X的熵就是所有信息量的期望
$$
H(X) = -[p(A)log(p(A))+p(B)log(p(B))+p(C)log(p(C))]
$$

## 相对熵（KL散度）

如果我们对于同一个随机变量x有两个单独的概率分布P(x)和Q(x),我们可以使用KL散度来衡量这两个分布的差异
$$
D_{KL}(p||q)=\sum_{i=1}^{n}p(x_{i})log(\frac{p(x_{i})}{q(x_{i})})
$$
D越小，表示q分布和p分布越接近

## 交叉熵

$$
\begin{equation}
\begin{aligned}
D_{KL}(p||q)&=\sum_{i=1}^{n}p(x_{i})log(\frac{p(x_{i})}{q(x_{i})})\\
&=\sum_{i=1}^{n} p(x_i)log(p(x_{i})) - \sum_{i=1}^{n}p(x_{i})log(q(x_{i}))\\
&=-H(p(x))+[-\sum_{i=1}^{n}p(x_{i})log(q(x_{i}))]\\
&=-H(p(x))+H(p,q)\\
\end{aligned}
\end{equation}
$$

$$
H(p,q)=-\sum_{i=1}^{n}p(x_{i})log(q(x_{i}))
$$

由于对于一个给定的p分布，其对应的熵H(p(x))是固定的，所以描述p，q两个分布差异完全由H(p,q)决定，即交叉熵

### 交叉熵在多分类的应用

$$
Loss=-\frac{1}{N}\sum_{i=1}^{N}y_{i}log(p_{i})
$$

这种写法的理解：yi在这里对应的是one-hot编码中为1的那个类别，pi则是预测出这个类别的概率，**都是一个值**

$$
Loss=-\frac{1}{N}\sum_{i=1}^{N}\sum_{c=1}^{C}y_{i}log(p_{i})
$$

这种写法yi是一个长度为C的one-hot向量，pi也是整个概率分布向量

### 交叉熵在二分类的应用

当C=2时(假设两个类别分别是猫和狗)，因为一共就两个取值，可以用一维的数字进行表示，如果用yi表示groundtruth是猫的概率，则groundtruth是狗的概率是1-yi，

$$
Loss=-\frac{1}{N}\sum_{i=1}^{N}[y_{i}log(p_{i})+(1-y_{i})log(1-p_{i})]
$$


# brain storming

* 先进行mask训练,相当于二值化训练,再进行每个像素点的训练,看是否这样的训练更容易收敛

* latex公式对齐：

  **\begin{aligned}**

  **a &=1\\\\**

  **&=**

  **\end{aligned}**

   用aligned包裹住，用\\\换行，在所有的等号前加上&

* np.array和np.asarray的区别：

  array是复制源数据的副本，开辟新的内存空间；asarray相当于将源数据换成ndarray的格式，会随着源数据改变而改变